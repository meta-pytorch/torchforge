# Grouped Relative Policy Optimization (GRPO)

# Global configuration
group_size: 8
batch_size: 16
max_req_tokens: 512
max_res_tokens: 512
model: "Qwen/Qwen3-14B"
off_by_n: 1 # Off by one by default
scheduler: mast
job_name: forge-qwen-14B
checkpoint_folder: /mnt/wsfuse/rithesh/forge_runs/${job_name}/23


# Dataset configuration
dataset:
  path: "openai/gsm8k"
  revision: "main"
  data_split: "train"
  streaming: true
  model: ${model}

# Policy configuration
policy:
  engine_config:
    model: /mnt/wsfuse/huggingface_models/models--Qwen--Qwen3-14B/snapshots/8268fe3026cb304910457689366670e803a6fd56
    tensor_parallel_size: 2
    pipeline_parallel_size: 1
    enforce_eager: false
    # TODO: Had to disable this becasue vLLm wouldn't like
    # need to revisit.
    disable_custom_all_reduce: true
  sampling_config:
    n: ${group_size}
    max_tokens: ${max_res_tokens}
    temperature: 1.0
    top_p: 1.0
  checkpoint_path: ${checkpoint_folder}

# Trainer configuration
trainer:
  model:
    name: qwen3
    flavor: 14B
    hf_assets_path: /mnt/wsfuse/huggingface_models/models--Qwen--Qwen3-14B/snapshots/8268fe3026cb304910457689366670e803a6fd56
  optimizer:
    name: AdamW
    lr: 1e-5
    eps: 1e-8
  lr_scheduler:
    warmup_steps: 1
  training:
    local_batch_size: ${batch_size}
    seq_len: 2048
    max_norm: 1.0
    steps: 1000000
    dtype: bfloat16
    gc_freq: 1
  compile:
    enable: false
  parallelism:
    data_parallel_replicate_degree: 1
    data_parallel_shard_degree: 4
    tensor_parallel_degree: 2
    pipeline_parallel_degree: 1
    context_parallel_degree: 1
    expert_parallel_degree: 1
    disable_loss_parallel: true
  checkpoint:
    enable: true
    initial_load_path: /mnt/wsfuse/huggingface_models/models--Qwen--Qwen3-14B/snapshots/8268fe3026cb304910457689366670e803a6fd56
    initial_load_in_hf: true
    last_save_in_hf: true
    interval: 500
    async_mode: "disabled"
    folder: ${checkpoint_folder}
  activation_checkpoint:
    mode: selective
    selective_ac_option: op
  comm:
    # TODO: revisit this. causing NCCL timeouts on inits when loading CP
    # from oilfs if the traienr is not in the same region as in PCI
    init_timeout_seconds: 3600
  use_dcp: true
  dcp_path: ${checkpoint_folder}

# Replay buffer configuration
replay_buffer:
  batch_size: ${batch_size}
  max_policy_age: ${off_by_n}
  dp_size: ${trainer.parallelism.data_parallel_shard_degree} # Must equal trainer DP degree

# Reference model configuration
ref_model:
  model:
    name: qwen3
    flavor: 14B
    hf_assets_path: /mnt/wsfuse/huggingface_models/models--Qwen--Qwen3-14B/snapshots/8268fe3026cb304910457689366670e803a6fd56
  training:
    dtype: bfloat16
    gc_freq: 1
  compile:
    enable: false
  parallelism:
    data_parallel_replicate_degree: 1
    data_parallel_shard_degree: 1
    tensor_parallel_degree: 1
    pipeline_parallel_degree: 1
    context_parallel_degree: 1
    expert_parallel_degree: 1
  checkpoint:
    initial_load_path: /mnt/wsfuse/huggingface_models/models--Qwen--Qwen3-14B/snapshots/8268fe3026cb304910457689366670e803a6fd56
    initial_load_in_hf: true

# All resource allocations
services:
  dataset:
    procs: 1
    num_replicas: 1
    with_gpus: false
    mesh_name: dataset
  policy:
    procs: ${policy.engine_config.tensor_parallel_size}
    num_replicas: 4
    with_gpus: true
    hosts: 1
    mesh_name: policy
  trainer:
    procs: 8
    num_replicas: 1
    with_gpus: true
    hosts: 1
    mesh_name: trainer
  replay_buffer:
    procs: 1
    num_replicas: 1
    with_gpus: false
    mesh_name: replay_buffer
  ref_model:
    procs: ${ref_model.parallelism.tensor_parallel_degree}
    num_replicas: 4
    with_gpus: true
    hosts: 1
    mesh_name: ref_model
  compute_advantages:
    procs: 1
    num_replicas: 1
    with_gpus: false
    mesh_name: compute_advantages
  reward_actor:
    procs: 1
    num_replicas: 1
    with_gpus: false
    mesh_name: reward_actor
